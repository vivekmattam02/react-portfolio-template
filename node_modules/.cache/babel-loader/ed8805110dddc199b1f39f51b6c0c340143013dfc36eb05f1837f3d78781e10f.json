{"ast":null,"code":"import React from\"react\";import\"../assets/styles/Project.scss\";// Use existing mock images to avoid file-not-found errors\nimport datacenter from'../assets/images/datacenter.jpg';import esvc from'../assets/images/esvc.jpg';import vip from'../assets/images/vip.jpg';import bark from'../assets/images/bark.jpg';import slap from'../assets/images/slap.jpg';import{jsx as _jsx,jsxs as _jsxs}from\"react/jsx-runtime\";function Project(){return/*#__PURE__*/_jsxs(\"div\",{className:\"projects-container\",id:\"projects\",children:[/*#__PURE__*/_jsx(\"h1\",{children:\"Projects\"}),/*#__PURE__*/_jsxs(\"div\",{className:\"projects-grid\",children:[/*#__PURE__*/_jsxs(\"div\",{className:\"project\",children:[/*#__PURE__*/_jsx(\"img\",{src:datacenter,className:\"zoom\",alt:\"HSRN Robot\",width:\"50%\"}),/*#__PURE__*/_jsx(\"h2\",{children:\"HSRN Robot \\u2013 Data Center Robot\"}),/*#__PURE__*/_jsx(\"p\",{children:\"The HSRN Robot Project at NYU focuses on developing a joystick-driven robotic system for data center automation, enabling precise navigation and real-time task execution. My role as a Developer involves designing robotic perception models and multi-agent coordination strategies to improve efficiency and reliability in structured environments.\"}),/*#__PURE__*/_jsx(\"p\",{children:\"Currently, I am working on sensor fusion techniques to enhance robotic perception, allowing the system to process and interpret data more accurately in real time. Additionally, I am developing multi-agent control algorithms, ensuring multiple robots can coordinate tasks effectively without conflicts or inefficiencies.\"}),/*#__PURE__*/_jsx(\"p\",{children:\"To achieve seamless integration, I am implementing Corelink C++ client with ROS, allowing for efficient communication between the robotic system and the central control network. The joystick-based interface ensures precise manual control while maintaining the flexibility for future autonomous operations.\"}),/*#__PURE__*/_jsxs(\"p\",{children:[/*#__PURE__*/_jsx(\"strong\",{children:\"Technologies:\"}),\" ROS, C++, Python, Corelink, Sensor Fusion\"]})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"project\",children:[/*#__PURE__*/_jsx(\"img\",{src:vip,className:\"zoom\",alt:\"NYU Self-Drive\",width:\"50%\"}),/*#__PURE__*/_jsx(\"h2\",{children:\"NYU VIP Self-Drive \\u2013 Autonomous Navigation & Visual SLAM\"}),/*#__PURE__*/_jsx(\"p\",{children:\"The NYU VIP Self-Drive project is a research initiative focused on developing autonomous navigation and mapping capabilities for small-scale indoor robotic vehicles. Our goal is to achieve efficient self-driving behavior in unknown environments using Visual SLAM, feature-based navigation, and real-time motion planning.\"}),/*#__PURE__*/_jsx(\"p\",{children:\"I\\u2019m currently working on path planning, SLAM integration, and robot localization, using A* search for optimal pathfinding and ORB feature matching for vision-based landmark recognition. The system operates on ROS 2 Humble, utilizing a monocular camera for mapping and a TurtleBot3 platform for real-time testing.\"}),/*#__PURE__*/_jsx(\"p\",{children:\"A key challenge is ensuring accurate navigation with minimal sensor data, requiring advanced graph-based planning and efficient exploration strategies. The final stage of development will focus on competing in the Self-Drive Exploration & Navigation Challenge.\"}),/*#__PURE__*/_jsxs(\"p\",{children:[/*#__PURE__*/_jsx(\"strong\",{children:\"Technologies:\"}),\" ROS 2 Humble, A*, ORB SLAM, TurtleBot3, OpenCV, C++\"]})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"project\",children:[/*#__PURE__*/_jsx(\"img\",{src:slap,className:\"zoom\",alt:\"S.L.A.P. Hand\",width:\"50%\"}),/*#__PURE__*/_jsx(\"h2\",{children:\"The S.L.A.P. Hand \\u2013 Evolving My Animatronic Hand Project\"}),/*#__PURE__*/_jsx(\"p\",{children:\"The S.L.A.P. Hand (Simultaneous Linked Articulation Project) is an advanced version of my undergraduate Animatronic Hand project, designed for remote operation and hazardous material handling. I\\u2019m currently focused on improving control accuracy, articulation, and response time by integrating Wi-Fi-based communication, gesture tracking, and haptic feedback.\"}),/*#__PURE__*/_jsx(\"p\",{children:\"This project is still in progress, and the next steps involve transitioning from Bluetooth to a more stable wired communication system, improving motor response times, and fine-tuning gesture-based articulation. Future plans include integrating cameras on the fingers for real-time object detection and exploring AI-driven grasp optimization.\"}),/*#__PURE__*/_jsxs(\"p\",{children:[/*#__PURE__*/_jsx(\"strong\",{children:\"Technologies:\"}),\" ESP8266, MPU6050, Haptic Feedback, Wi-Fi Communication\"]})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"project\",children:[/*#__PURE__*/_jsx(\"h2\",{children:\"Foundations of Robotics \\u2013 SCARA Manipulator Control & Planning\"}),/*#__PURE__*/_jsx(\"p\",{children:\"This project was a three-phase exploration into robotic motion control, completed during my first semester at NYU as part of the \\\"Foundations of Robotics\\\" course. Using a 4-DOF SCARA manipulator, I progressively built systems for kinematic control, real-time error correction, obstacle avoidance, and dynamic trajectory execution in simulated environments. The project was developed entirely in MATLAB and Simulink, with each phase building on the last to reflect increasingly realistic robotic behaviors.\"}),/*#__PURE__*/_jsx(\"p\",{children:\"In the first phase, I implemented basic inverse kinematics algorithms using both the Jacobian Inverse and Jacobian Transpose methods. These were applied to track a predefined Cartesian trajectory by translating end-effector positions into joint-level motions. This initial setup helped me understand the mathematical foundations of robot control and how Euler integration (1 ms timestep) can be used to simulate smooth joint movements.\"}),/*#__PURE__*/_jsx(\"p\",{children:\"The second phase introduced real-time adaptability. I implemented second-order inverse kinematics to improve tracking accuracy and extended the system to avoid dynamic obstacles in the workspace. By using a Jacobian Pseudo-Inverse with Null-Space Projection, I enabled the manipulator to prioritize trajectory tracking in the x-y plane while dynamically adjusting in the z-direction to avoid collisions. This approach helped me experiment with redundancy resolution and secondary task execution, which are essential in complex robotic systems.\"}),/*#__PURE__*/_jsx(\"p\",{children:\"The final phase combined trajectory planning with inverse dynamic control. I designed a smooth, multi-waypoint Cartesian trajectory using trapezoidal velocity profiles and anticipation timing to ensure continuity. Then, I implemented a control system that accounted for the robot\\u2019s dynamic behavior under varying load conditions. The SCARA manipulator was simulated using a second-order inverse kinematics model that generated torque commands for precise execution. This phase gave me hands-on insight into how real robots operate under physical constraints like inertia and external forces.\"}),/*#__PURE__*/_jsxs(\"p\",{children:[/*#__PURE__*/_jsx(\"strong\",{children:\"Tools & Frameworks:\"}),\" MATLAB, Simulink, SCARA Simulation, VR Visualization\",/*#__PURE__*/_jsx(\"br\",{}),/*#__PURE__*/_jsx(\"strong\",{children:\"Key Concepts:\"}),\" Inverse Kinematics, Null-Space Control, Trajectory Planning, Inverse Dynamics, Redundancy Resolution, Real-Time Motion Correction\"]})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"project\",children:[/*#__PURE__*/_jsx(\"img\",{src:bark,className:\"zoom\",alt:\"B.A.R.K. Door\",width:\"50%\"}),/*#__PURE__*/_jsx(\"h2\",{children:\"B.A.R.K. Door \\u2013 Smart Pet Access System\"}),/*#__PURE__*/_jsx(\"p\",{children:\"B.A.R.K. (Bluetooth Actuated Remote Key) Door is a smart pet-access system I developed to enable secure, automated pet entry while preventing unauthorized access. The system uses RFID authentication, Bluetooth connectivity, and IoT-based monitoring.\"}),/*#__PURE__*/_jsx(\"p\",{children:\"I designed and implemented the system with BS2-controlled servo mechanisms, an RFID-based locking system, and Bluetooth-based manual override via a mobile app. Currently, I\\u2019m exploring Wi-Fi integration and AI-driven behavioral tracking to enhance access security and adaptability.\"}),/*#__PURE__*/_jsxs(\"p\",{children:[/*#__PURE__*/_jsx(\"strong\",{children:\"Technologies:\"}),\" BS2, RFID, Bluetooth, IoT, Servo Mechanisms\"]})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"project\",children:[/*#__PURE__*/_jsx(\"img\",{src:esvc,className:\"zoom\",alt:\"E.S.V.C. Project\",width:\"50%\"}),/*#__PURE__*/_jsx(\"h2\",{children:\"E.S.V.C. \\u2013 Solar-Powered Electric Vehicle\"}),/*#__PURE__*/_jsx(\"p\",{children:\"The E.S.V.C. (Electric Solar Vehicle Championship) project focused on developing an electric solar vehicle designed for sustainability and efficient mobility. As part of Team Solarians 4.0 (ESVC-22-1498), I was responsible for designing and structurally analyzing a lightweight tubular chassis using CATIA V5 and ANSYS R16.2 software.\"}),/*#__PURE__*/_jsx(\"p\",{children:\"The chassis, engineered from AISI 4130 steel, ensured robustness under dynamic and impact loads. The design adhered to E.S.V.C. rulebook guidelines, emphasizing safety, vehicle stability, and optimal performance in competition conditions.\"}),/*#__PURE__*/_jsxs(\"p\",{children:[/*#__PURE__*/_jsx(\"strong\",{children:\"Technologies:\"}),\" CATIA V5, ANSYS R16.2.\"]})]})]})]});}export default Project;","map":{"version":3,"names":["React","datacenter","esvc","vip","bark","slap","jsx","_jsx","jsxs","_jsxs","Project","className","id","children","src","alt","width"],"sources":["/home/vivek/Desktop/react-portfolio-template-master/src/components/Project.tsx"],"sourcesContent":["import React from \"react\";\nimport \"../assets/styles/Project.scss\";\n\n// Use existing mock images to avoid file-not-found errors\nimport datacenter from '../assets/images/datacenter.jpg';\nimport esvc from '../assets/images/esvc.jpg';\nimport vip from '../assets/images/vip.jpg';\nimport bark from '../assets/images/bark.jpg';\nimport slap from '../assets/images/slap.jpg';\n\nfunction Project() {\n  return (\n    <div className=\"projects-container\" id=\"projects\">\n      <h1>Projects</h1>\n      <div className=\"projects-grid\">\n\n        {/* 1) HSRN Robot – Data Center Robot */}\n        <div className=\"project\">\n          <img src={datacenter} className=\"zoom\" alt=\"HSRN Robot\" width=\"50%\" />\n          <h2>HSRN Robot – Data Center Robot</h2>\n          <p>\n            The HSRN Robot Project at NYU focuses on developing a joystick-driven robotic system \n            for data center automation, enabling precise navigation and real-time task execution. \n            My role as a Developer involves designing robotic perception models and multi-agent \n            coordination strategies to improve efficiency and reliability in structured environments.\n          </p>\n          <p>\n            Currently, I am working on sensor fusion techniques to enhance robotic perception, \n            allowing the system to process and interpret data more accurately in real time. \n            Additionally, I am developing multi-agent control algorithms, ensuring multiple robots \n            can coordinate tasks effectively without conflicts or inefficiencies.\n          </p>\n          <p>\n            To achieve seamless integration, I am implementing Corelink C++ client with ROS, \n            allowing for efficient communication between the robotic system and the central \n            control network. The joystick-based interface ensures precise manual control while \n            maintaining the flexibility for future autonomous operations.\n          </p>\n          <p><strong>Technologies:</strong> ROS, C++, Python, Corelink, Sensor Fusion</p>\n        </div>\n\n        {/* 2) NYU VIP Self-Drive – Autonomous Navigation & Visual SLAM */}\n        <div className=\"project\">\n          <img src={vip} className=\"zoom\" alt=\"NYU Self-Drive\" width=\"50%\" />\n          <h2>NYU VIP Self-Drive – Autonomous Navigation & Visual SLAM</h2>\n          <p>\n            The NYU VIP Self-Drive project is a research initiative focused on developing \n            autonomous navigation and mapping capabilities for small-scale indoor robotic vehicles. \n            Our goal is to achieve efficient self-driving behavior in unknown environments \n            using Visual SLAM, feature-based navigation, and real-time motion planning.\n          </p>\n          <p>\n            I’m currently working on path planning, SLAM integration, and robot localization, \n            using A* search for optimal pathfinding and ORB feature matching for vision-based \n            landmark recognition. The system operates on ROS 2 Humble, utilizing a monocular camera \n            for mapping and a TurtleBot3 platform for real-time testing.\n          </p>\n          <p>\n            A key challenge is ensuring accurate navigation with minimal sensor data, requiring \n            advanced graph-based planning and efficient exploration strategies. The final stage \n            of development will focus on competing in the Self-Drive Exploration & Navigation Challenge.\n          </p>\n          <p><strong>Technologies:</strong> ROS 2 Humble, A*, ORB SLAM, TurtleBot3, OpenCV, C++</p>\n        </div>\n\n        {/* 3) The S.L.A.P. Hand – Evolving My Animatronic Hand Project */}\n        <div className=\"project\">\n          <img src={slap} className=\"zoom\" alt=\"S.L.A.P. Hand\" width=\"50%\" />\n          <h2>The S.L.A.P. Hand – Evolving My Animatronic Hand Project</h2>\n          <p>\n            The S.L.A.P. Hand (Simultaneous Linked Articulation Project) is an advanced version \n            of my undergraduate Animatronic Hand project, designed for remote operation and \n            hazardous material handling. I’m currently focused on improving control accuracy, \n            articulation, and response time by integrating Wi-Fi-based communication, gesture \n            tracking, and haptic feedback.\n          </p>\n          <p>\n            This project is still in progress, and the next steps involve transitioning from \n            Bluetooth to a more stable wired communication system, improving motor response times, \n            and fine-tuning gesture-based articulation. Future plans include integrating cameras on \n            the fingers for real-time object detection and exploring AI-driven grasp optimization.\n          </p>\n          <p><strong>Technologies:</strong> ESP8266, MPU6050, Haptic Feedback, Wi-Fi Communication</p>\n        </div>\n        {/* 4) Foundations of Robotics – SCARA Manipulator Control & Planning */}\n        <div className=\"project\">\n        <h2>Foundations of Robotics – SCARA Manipulator Control & Planning</h2>\n         <p>\n          This project was a three-phase exploration into robotic motion control, completed during my first semester at NYU \n          as part of the \"Foundations of Robotics\" course. Using a 4-DOF SCARA manipulator, I progressively built systems for \n          kinematic control, real-time error correction, obstacle avoidance, and dynamic trajectory execution in simulated environments. \n          The project was developed entirely in MATLAB and Simulink, with each phase building on the last to reflect increasingly realistic robotic behaviors.\n          </p>\n          <p>\n            In the first phase, I implemented basic inverse kinematics algorithms using both the Jacobian Inverse and Jacobian Transpose methods. \n            These were applied to track a predefined Cartesian trajectory by translating end-effector positions into joint-level motions. \n            This initial setup helped me understand the mathematical foundations of robot control and how Euler integration (1 ms timestep) \n            can be used to simulate smooth joint movements.\n          </p>\n          <p>\n          The second phase introduced real-time adaptability. I implemented second-order inverse kinematics to improve tracking accuracy \n          and extended the system to avoid dynamic obstacles in the workspace. By using a Jacobian Pseudo-Inverse with Null-Space Projection, \n          I enabled the manipulator to prioritize trajectory tracking in the x-y plane while dynamically adjusting in the z-direction to avoid collisions. \n          This approach helped me experiment with redundancy resolution and secondary task execution, which are essential in complex robotic systems.\n          </p>\n          <p>\n          The final phase combined trajectory planning with inverse dynamic control. I designed a smooth, multi-waypoint Cartesian trajectory \n          using trapezoidal velocity profiles and anticipation timing to ensure continuity. Then, I implemented a control system that accounted \n          for the robot’s dynamic behavior under varying load conditions. The SCARA manipulator was simulated using a second-order inverse \n          kinematics model that generated torque commands for precise execution. This phase gave me hands-on insight into how real robots operate \n          under physical constraints like inertia and external forces.\n          </p>\n          \n          <p>\n            <strong>Tools & Frameworks:</strong> MATLAB, Simulink, SCARA Simulation, VR Visualization<br/>\n            <strong>Key Concepts:</strong> Inverse Kinematics, Null-Space Control, Trajectory Planning, Inverse Dynamics, Redundancy Resolution, Real-Time Motion Correction\n          </p>\n        </div>\n\n        {/* 5) B.A.R.K. Door – Smart Pet Access System */}\n        <div className=\"project\">\n          <img src={bark} className=\"zoom\" alt=\"B.A.R.K. Door\" width=\"50%\" />\n          <h2>B.A.R.K. Door – Smart Pet Access System</h2>\n          <p>\n            B.A.R.K. (Bluetooth Actuated Remote Key) Door is a smart pet-access system I developed to \n            enable secure, automated pet entry while preventing unauthorized access. The system \n            uses RFID authentication, Bluetooth connectivity, and IoT-based monitoring.\n          </p>\n          <p>\n            I designed and implemented the system with BS2-controlled servo mechanisms, \n            an RFID-based locking system, and Bluetooth-based manual override via a mobile app. \n            Currently, I’m exploring Wi-Fi integration and AI-driven behavioral tracking to enhance \n            access security and adaptability.\n          </p>\n          <p><strong>Technologies:</strong> BS2, RFID, Bluetooth, IoT, Servo Mechanisms</p>\n        </div>\n\n        {/* 6) E.S.V.C. – Solar-Powered Electric Vehicle for Sustainable Mobility */}\n        <div className=\"project\">\n          <img src={esvc} className=\"zoom\" alt=\"E.S.V.C. Project\" width=\"50%\" />\n          <h2>E.S.V.C. – Solar-Powered Electric Vehicle</h2>\n          <p>\n            The E.S.V.C. (Electric Solar Vehicle Championship) project focused on developing \n            an electric solar vehicle designed for sustainability and efficient mobility. \n            As part of Team Solarians 4.0 (ESVC-22-1498), I was responsible for designing \n            and structurally analyzing a lightweight tubular chassis using CATIA V5 and \n            ANSYS R16.2 software.\n          </p>\n          <p>\n            The chassis, engineered from AISI 4130 steel, ensured robustness under dynamic \n            and impact loads. The design adhered to E.S.V.C. rulebook guidelines, emphasizing \n            safety, vehicle stability, and optimal performance in competition conditions.\n          </p>\n          \n          <p><strong>Technologies:</strong> CATIA V5, ANSYS R16.2.</p>\n        </div>\n\n      </div>\n    </div>\n  );\n}\n\nexport default Project;\n"],"mappings":"AAAA,MAAO,CAAAA,KAAK,KAAM,OAAO,CACzB,MAAO,+BAA+B,CAEtC;AACA,MAAO,CAAAC,UAAU,KAAM,iCAAiC,CACxD,MAAO,CAAAC,IAAI,KAAM,2BAA2B,CAC5C,MAAO,CAAAC,GAAG,KAAM,0BAA0B,CAC1C,MAAO,CAAAC,IAAI,KAAM,2BAA2B,CAC5C,MAAO,CAAAC,IAAI,KAAM,2BAA2B,CAAC,OAAAC,GAAA,IAAAC,IAAA,CAAAC,IAAA,IAAAC,KAAA,yBAE7C,QAAS,CAAAC,OAAOA,CAAA,CAAG,CACjB,mBACED,KAAA,QAAKE,SAAS,CAAC,oBAAoB,CAACC,EAAE,CAAC,UAAU,CAAAC,QAAA,eAC/CN,IAAA,OAAAM,QAAA,CAAI,UAAQ,CAAI,CAAC,cACjBJ,KAAA,QAAKE,SAAS,CAAC,eAAe,CAAAE,QAAA,eAG5BJ,KAAA,QAAKE,SAAS,CAAC,SAAS,CAAAE,QAAA,eACtBN,IAAA,QAAKO,GAAG,CAAEb,UAAW,CAACU,SAAS,CAAC,MAAM,CAACI,GAAG,CAAC,YAAY,CAACC,KAAK,CAAC,KAAK,CAAE,CAAC,cACtET,IAAA,OAAAM,QAAA,CAAI,qCAA8B,CAAI,CAAC,cACvCN,IAAA,MAAAM,QAAA,CAAG,0VAKH,CAAG,CAAC,cACJN,IAAA,MAAAM,QAAA,CAAG,iUAKH,CAAG,CAAC,cACJN,IAAA,MAAAM,QAAA,CAAG,mTAKH,CAAG,CAAC,cACJJ,KAAA,MAAAI,QAAA,eAAGN,IAAA,WAAAM,QAAA,CAAQ,eAAa,CAAQ,CAAC,6CAA0C,EAAG,CAAC,EAC5E,CAAC,cAGNJ,KAAA,QAAKE,SAAS,CAAC,SAAS,CAAAE,QAAA,eACtBN,IAAA,QAAKO,GAAG,CAAEX,GAAI,CAACQ,SAAS,CAAC,MAAM,CAACI,GAAG,CAAC,gBAAgB,CAACC,KAAK,CAAC,KAAK,CAAE,CAAC,cACnET,IAAA,OAAAM,QAAA,CAAI,+DAAwD,CAAI,CAAC,cACjEN,IAAA,MAAAM,QAAA,CAAG,kUAKH,CAAG,CAAC,cACJN,IAAA,MAAAM,QAAA,CAAG,+TAKH,CAAG,CAAC,cACJN,IAAA,MAAAM,QAAA,CAAG,sQAIH,CAAG,CAAC,cACJJ,KAAA,MAAAI,QAAA,eAAGN,IAAA,WAAAM,QAAA,CAAQ,eAAa,CAAQ,CAAC,uDAAoD,EAAG,CAAC,EACtF,CAAC,cAGNJ,KAAA,QAAKE,SAAS,CAAC,SAAS,CAAAE,QAAA,eACtBN,IAAA,QAAKO,GAAG,CAAET,IAAK,CAACM,SAAS,CAAC,MAAM,CAACI,GAAG,CAAC,eAAe,CAACC,KAAK,CAAC,KAAK,CAAE,CAAC,cACnET,IAAA,OAAAM,QAAA,CAAI,+DAAwD,CAAI,CAAC,cACjEN,IAAA,MAAAM,QAAA,CAAG,6WAMH,CAAG,CAAC,cACJN,IAAA,MAAAM,QAAA,CAAG,wVAKH,CAAG,CAAC,cACJJ,KAAA,MAAAI,QAAA,eAAGN,IAAA,WAAAM,QAAA,CAAQ,eAAa,CAAQ,CAAC,0DAAuD,EAAG,CAAC,EACzF,CAAC,cAENJ,KAAA,QAAKE,SAAS,CAAC,SAAS,CAAAE,QAAA,eACxBN,IAAA,OAAAM,QAAA,CAAI,qEAA8D,CAAI,CAAC,cACtEN,IAAA,MAAAM,QAAA,CAAG,6fAKF,CAAG,CAAC,cACJN,IAAA,MAAAM,QAAA,CAAG,qbAKH,CAAG,CAAC,cACJN,IAAA,MAAAM,QAAA,CAAG,iiBAKH,CAAG,CAAC,cACJN,IAAA,MAAAM,QAAA,CAAG,slBAMH,CAAG,CAAC,cAEJJ,KAAA,MAAAI,QAAA,eACEN,IAAA,WAAAM,QAAA,CAAQ,qBAAmB,CAAQ,CAAC,wDAAqD,cAAAN,IAAA,QAAI,CAAC,cAC9FA,IAAA,WAAAM,QAAA,CAAQ,eAAa,CAAQ,CAAC,qIAChC,EAAG,CAAC,EACD,CAAC,cAGNJ,KAAA,QAAKE,SAAS,CAAC,SAAS,CAAAE,QAAA,eACtBN,IAAA,QAAKO,GAAG,CAAEV,IAAK,CAACO,SAAS,CAAC,MAAM,CAACI,GAAG,CAAC,eAAe,CAACC,KAAK,CAAC,KAAK,CAAE,CAAC,cACnET,IAAA,OAAAM,QAAA,CAAI,8CAAuC,CAAI,CAAC,cAChDN,IAAA,MAAAM,QAAA,CAAG,2PAIH,CAAG,CAAC,cACJN,IAAA,MAAAM,QAAA,CAAG,gSAKH,CAAG,CAAC,cACJJ,KAAA,MAAAI,QAAA,eAAGN,IAAA,WAAAM,QAAA,CAAQ,eAAa,CAAQ,CAAC,+CAA4C,EAAG,CAAC,EAC9E,CAAC,cAGNJ,KAAA,QAAKE,SAAS,CAAC,SAAS,CAAAE,QAAA,eACtBN,IAAA,QAAKO,GAAG,CAAEZ,IAAK,CAACS,SAAS,CAAC,MAAM,CAACI,GAAG,CAAC,kBAAkB,CAACC,KAAK,CAAC,KAAK,CAAE,CAAC,cACtET,IAAA,OAAAM,QAAA,CAAI,gDAAyC,CAAI,CAAC,cAClDN,IAAA,MAAAM,QAAA,CAAG,gVAMH,CAAG,CAAC,cACJN,IAAA,MAAAM,QAAA,CAAG,gPAIH,CAAG,CAAC,cAEJJ,KAAA,MAAAI,QAAA,eAAGN,IAAA,WAAAM,QAAA,CAAQ,eAAa,CAAQ,CAAC,0BAAuB,EAAG,CAAC,EACzD,CAAC,EAEH,CAAC,EACH,CAAC,CAEV,CAEA,cAAe,CAAAH,OAAO","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}